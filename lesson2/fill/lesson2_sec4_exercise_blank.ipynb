{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson2 畳み込みニューラルネットワーク (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目次\n",
    "\n",
    "- Section1 解説\n",
    "  - 1.1 CNN基礎\n",
    "  - 1.2 Convolution(畳み込み)層\n",
    "  - 1.3 Pooling(プーリング)層\n",
    "  - 1.4 確認問題\n",
    "\n",
    "- Section2 実装①\n",
    "  - 2.1 Fasion MNISTをCNNでクラス分類\n",
    "  - 2.2 CIFAR10のデータをCNNでクラス分類\n",
    "  \n",
    "- Section3 テクニック・発展内容\n",
    "  - 3.1 Data Augmentation\n",
    "  - 3.2 画像データの正規化\n",
    "  - 3.3 Batch Normalization\n",
    "  - 3.4 Skip Connection  (Residual Network)\n",
    "  - 3.5 学習済みネットワークの利用\n",
    "  - 3.6 学習させたモデルの保存・再利用\n",
    "  - 3.7 確認問題\n",
    "\n",
    "- Section4 実装②\n",
    "  - 4.1 CIFAR10のデータをCNNでクラス分類②\n",
    "\n",
    "- Section5 ケーススタディ\n",
    "\n",
    "- Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 の解答\n",
    "\n",
    "問1: ② 問2: ① 問3: ① 問4: ①"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Input, Activation, add, Add, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.datasets import cifar10\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section4 実装②"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 CIFAR10のデータをCNNでクラス分類②"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255\n",
    "y_train = np.eye(10)[y_train.astype('int32').flatten()]\n",
    "\n",
    "x_test = x_test.astype('float32') / 255\n",
    "y_test = np.eye(10)[y_test.astype('int32').flatten()]\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    x_train, y_train, test_size=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section3の学習内容も踏まえて、CIFAR10のクラス分類を行いたいと思います。\n",
    "\n",
    "まず、モデルの作成を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(6, kernel_size=(5, 5), activation='relu',\n",
    "                 kernel_initializer='he_normal', input_shape=(32, 32, 3)))  # 32x32x3 -> 28x28x6\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))  # 28x28x6 -> 14x14x6\n",
    "model.add(Conv2D(16, kernel_size=(5, 5), activation='relu',\n",
    "                 kernel_initializer='he_normal'))  # 14x14x6 -> 10x10x16\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))  # 10x10x16 -> 5x5x16\n",
    "\n",
    "model.add(Flatten())  # 5x5x16 -> 400\n",
    "model.add(Dense(120, activation='relu',\n",
    "                kernel_initializer='he_normal'))  # 400 ->120\n",
    "model.add(Dense(84, activation='relu', kernel_initializer='he_normal'))  # 120 ->84\n",
    "model.add(Dense(10, activation='softmax'))  # 84 ->10\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.categorical_crossentropy,\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、Section3で学習したDataAugumentationや画像データの正規化を学習に反映させてみます。\n",
    "\n",
    "kerasのImageDataGeneratorを使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    width_shift_range=0.2,  # 3.1.1 左右にずらす\n",
    "    height_shift_range=0.2,  # 3.1.2 上下にずらす\n",
    "    horizontal_flip=True,  # 3.1.3 左右反転\n",
    "    # 3.2.1 Global Contrast Normalization (GCN) (Falseに設定しているのでここでは使用していない)\n",
    "    samplewise_center=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False)  # 3.2.2 Zero-phase Component Analysis (ZCA) Whitening (Falseに設定しているのでここでは使用していない)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "400/400 [==============================] - 19s 48ms/step - loss: 1.8601 - acc: 0.3128 - val_loss: 1.6124 - val_acc: 0.4134\n",
      "Epoch 2/30\n",
      "400/400 [==============================] - 15s 37ms/step - loss: 1.6443 - acc: 0.3940 - val_loss: 1.4765 - val_acc: 0.4705\n",
      "Epoch 3/30\n",
      "400/400 [==============================] - 15s 37ms/step - loss: 1.5759 - acc: 0.4279 - val_loss: 1.4583 - val_acc: 0.4709\n",
      "Epoch 4/30\n",
      "400/400 [==============================] - 15s 37ms/step - loss: 1.5140 - acc: 0.4543 - val_loss: 1.3853 - val_acc: 0.5003\n",
      "Epoch 5/30\n",
      "400/400 [==============================] - 15s 38ms/step - loss: 1.4658 - acc: 0.4707 - val_loss: 1.3801 - val_acc: 0.4963\n",
      "Epoch 6/30\n",
      "400/400 [==============================] - 15s 37ms/step - loss: 1.4386 - acc: 0.4824 - val_loss: 1.3246 - val_acc: 0.5284\n",
      "Epoch 7/30\n",
      "400/400 [==============================] - 15s 37ms/step - loss: 1.4027 - acc: 0.4949 - val_loss: 1.2996 - val_acc: 0.5389\n",
      "Epoch 8/30\n",
      "400/400 [==============================] - 15s 37ms/step - loss: 1.3725 - acc: 0.5065 - val_loss: 1.2836 - val_acc: 0.5437\n",
      "Epoch 9/30\n",
      "400/400 [==============================] - 15s 38ms/step - loss: 1.3573 - acc: 0.5134 - val_loss: 1.2478 - val_acc: 0.5593\n",
      "Epoch 10/30\n",
      "400/400 [==============================] - 15s 38ms/step - loss: 1.3386 - acc: 0.5191 - val_loss: 1.1974 - val_acc: 0.5715\n",
      "Epoch 11/30\n",
      "400/400 [==============================] - 16s 39ms/step - loss: 1.3219 - acc: 0.5253 - val_loss: 1.1924 - val_acc: 0.5692\n",
      "Epoch 12/30\n",
      "400/400 [==============================] - 15s 38ms/step - loss: 1.3025 - acc: 0.5328 - val_loss: 1.1836 - val_acc: 0.5795\n",
      "Epoch 13/30\n",
      "400/400 [==============================] - 15s 38ms/step - loss: 1.2878 - acc: 0.5374 - val_loss: 1.1822 - val_acc: 0.5776\n",
      "Epoch 14/30\n",
      "400/400 [==============================] - 15s 38ms/step - loss: 1.2857 - acc: 0.5364 - val_loss: 1.1736 - val_acc: 0.5880\n",
      "Epoch 15/30\n",
      "400/400 [==============================] - 15s 38ms/step - loss: 1.2678 - acc: 0.5417 - val_loss: 1.1456 - val_acc: 0.5914\n",
      "Epoch 16/30\n",
      "400/400 [==============================] - 15s 37ms/step - loss: 1.2517 - acc: 0.5528 - val_loss: 1.1449 - val_acc: 0.5941\n",
      "Epoch 17/30\n",
      "400/400 [==============================] - 15s 37ms/step - loss: 1.2515 - acc: 0.5528 - val_loss: 1.1818 - val_acc: 0.5735\n",
      "Epoch 18/30\n",
      "400/400 [==============================] - 15s 38ms/step - loss: 1.2447 - acc: 0.5567 - val_loss: 1.1756 - val_acc: 0.5766\n",
      "Epoch 19/30\n",
      "400/400 [==============================] - 15s 37ms/step - loss: 1.2350 - acc: 0.5556 - val_loss: 1.1221 - val_acc: 0.6022\n",
      "Epoch 20/30\n",
      "400/400 [==============================] - 15s 38ms/step - loss: 1.2330 - acc: 0.5617 - val_loss: 1.1283 - val_acc: 0.5964\n",
      "Epoch 21/30\n",
      "400/400 [==============================] - 15s 37ms/step - loss: 1.2187 - acc: 0.5640 - val_loss: 1.1422 - val_acc: 0.5932\n",
      "Epoch 22/30\n",
      "400/400 [==============================] - 15s 38ms/step - loss: 1.2105 - acc: 0.5672 - val_loss: 1.1593 - val_acc: 0.5868\n",
      "Epoch 23/30\n",
      "400/400 [==============================] - 15s 38ms/step - loss: 1.2038 - acc: 0.5683 - val_loss: 1.1116 - val_acc: 0.6065\n",
      "Epoch 24/30\n",
      "400/400 [==============================] - 15s 37ms/step - loss: 1.1999 - acc: 0.5703 - val_loss: 1.0947 - val_acc: 0.6166\n",
      "Epoch 25/30\n",
      "400/400 [==============================] - 15s 37ms/step - loss: 1.1851 - acc: 0.5792 - val_loss: 1.1251 - val_acc: 0.6036\n",
      "Epoch 26/30\n",
      "400/400 [==============================] - 15s 37ms/step - loss: 1.1894 - acc: 0.5747 - val_loss: 1.1076 - val_acc: 0.6066\n",
      "Epoch 27/30\n",
      "400/400 [==============================] - 15s 36ms/step - loss: 1.1842 - acc: 0.5754 - val_loss: 1.0715 - val_acc: 0.6232\n",
      "Epoch 28/30\n",
      "400/400 [==============================] - 15s 37ms/step - loss: 1.1711 - acc: 0.5839 - val_loss: 1.0634 - val_acc: 0.6262\n",
      "Epoch 29/30\n",
      "400/400 [==============================] - 15s 37ms/step - loss: 1.1656 - acc: 0.5852 - val_loss: 1.0981 - val_acc: 0.6119\n",
      "Epoch 30/30\n",
      "400/400 [==============================] - 15s 37ms/step - loss: 1.1665 - acc: 0.5827 - val_loss: 1.0986 - val_acc: 0.6117\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f68b33d4be0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=100),\n",
    "                    steps_per_epoch=x_train.shape[0] // 100, epochs=30, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[0] // 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
